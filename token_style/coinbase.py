# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/coinbase.ipynb.

# %% auto 0
__all__ = ['retrieve_coinbase_price', 'coinbase_tokens', 'coinbase_usd_tokens', 'coinbase_price_history', 'save_file',
           'coinbase_to_file', 'read_all_files']

# %% ../nbs/coinbase.ipynb 3
from datetime import datetime
import pandas as pd
import requests
import os
import datetime as dt


# %% ../nbs/coinbase.ipynb 4
def retrieve_coinbase_price(pair="BTC-USD",time_interval=3600, 
                            end_date=datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'), 
                            start_date=(datetime.now()-pd.Timedelta(days=2)).strftime('%Y-%m-%dT%H:%M:%SZ')):
    # This function retrieves the price data from Coinbase for a given pair and time interval.
    # There is a limit of 300 requests per hour.
    # There is a maximum of 200 candles per request. If you need more, you need to paginate.
    # If you try to retrive more per hour or more candles per request, you will get a error, and the function will return None.
    # General URL is: https://api.exchange.coinbase.com/products/{pair}/candles
    # Important: time_interval is in seconds
    # For documentation see: https://docs.cdp.coinbase.com/exchange/reference/exchangerestapi_getproductcandles
    
    url = f"https://api.exchange.coinbase.com/products/{pair}/candles?granularity={time_interval}&start={start_date}&end={end_date}"
    response = requests.get(url)
    if response.status_code != 200:
        return None
    data = response.json()
    if not data:
        return None

    column_names = ['unix', 'low', 'high', 'open', 'close', 'volume']
    df = pd.DataFrame(data, columns=column_names)
    df['datetime'] = pd.to_datetime(df['unix'], unit='s')
    df['pair'] = pair
    df = df.sort_values(by='datetime')
    # drop unix column and put date first
    df = df.drop(columns=['unix'])
    df = df[['datetime'] + [col for col in df.columns if col != 'datetime']]
    return df


# %% ../nbs/coinbase.ipynb 5
def coinbase_tokens():
    currencies_url = "https://api.exchange.coinbase.com/products"
    currencies_response = requests.get(currencies_url)
    currencies_data = currencies_response.json()
    return pd.DataFrame(currencies_data)


# %% ../nbs/coinbase.ipynb 6
def coinbase_usd_tokens():
    tokens = coinbase_tokens()
    return tokens[tokens['quote_currency']=='USD']


# %% ../nbs/coinbase.ipynb 7
# Download long time series from Coinbase accounting for maximum number of dates per request
def coinbase_price_history(pair='BTC-USD',start_date='2024-01-01',end_date='2024-05-01',time_interval=3600,max_pull=250,verbose=False):
    # This function downloads the price history for a given pair from Coinbase.
    # It accounts for the maximum number of dates that can be downloaded at once. This can change in the future.

    # convert the dates to datetime
    start_date = pd.to_datetime(start_date)
    end_date = pd.to_datetime(end_date)
    if end_date < start_date:
        # raise an error
        raise ValueError("End date is smaller than start date")
    # calculate the number of hours between the start and end date
    n_hours = (end_date - start_date).days * 24
    if n_hours <= max_pull:
        df = retrieve_coinbase_price(pair,start_date=start_date.strftime('%Y-%m-%dT%H:%M:%SZ'),end_date=end_date.strftime('%Y-%m-%dT%H:%M:%SZ'),time_interval=time_interval)
        return df
    # create a timeline with the maximum number of dates per request
    time_line = pd.date_range(start=start_date, end=end_date, periods=n_hours//max_pull+1)
    price_list = []
    for i in range(len(time_line)-1):
        end = time_line[i+1]
        start = time_line[i]
        if verbose:
            print(f"Downloading data from {start} to {end}")
        df = retrieve_coinbase_price(pair,start_date=start.strftime('%Y-%m-%dT%H:%M:%SZ'),end_date=end.strftime('%Y-%m-%dT%H:%M:%SZ'),time_interval=time_interval)
        if df is not None:
            price_list.append(df)
    # concatenate the dataframes and sort by date and drop duplicates dates
    df = pd.concat(price_list)
    df = df.sort_values(by='datetime')
    df = df.drop_duplicates(subset='datetime').reset_index(drop=True)
    return df

# %% ../nbs/coinbase.ipynb 8
def save_file(df,folder_path,file_name,type="csv"):
    if type == "csv":
        df.to_csv(f"{folder_path}/{file_name}.csv",index=False)
    elif type == "parquet":
        df.to_parquet(f"{folder_path}/{file_name}.parquet")



# %% ../nbs/coinbase.ipynb 9
def coinbase_to_file(folder_path="../data/coinbase",token_list=coinbase_usd_tokens()['id'].tolist(),type="csv",
                     interval=3600,all_tokens=True):
    # Documentation:
    # This function downloads the price history for a given list of tokens from Coinbase and saves them in a folder.
    # If the folder does not exist, it creates it.
    # If the folder exists, it reads the existing files and appends the new data to them.
    # The files are saved in the folder with the name of the token and the extension of the type.
    # The files are saved in the format of the type.
    
    # create the folder if it does not exist, and if it exists, read the file names
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
    else:
        if all_tokens:
            file_names = os.listdir(folder_path)
            # remove the file extension
            tokens_in_folder = [os.path.splitext(file_name)[0] for file_name in file_names]
            # join tokens in folder with token_list and remove the duplicates
            token_list = list(set(token_list + tokens_in_folder))
    # loop over the token list and open the file if it exists and append the new data
    for token in token_list:
        print(f"Processing {token}")
        file_name = f"{folder_path}/{token}.{type}"
        if os.path.exists(file_name):
            if type == "csv":
                df = pd.read_csv(file_name)
            elif type == "parquet":
                df = pd.read_parquet(file_name)
            else:
                raise ValueError(f"Type {type} not supported")
            # read last date in the file
            last_date = pd.to_datetime(df['datetime'].iloc[-1])
            if interval == 3600:
                today = datetime.now(tz=dt.UTC).replace(minute=0,second=0,microsecond=0)
            else:
                today = datetime.now(tz=dt.UTC)
            #print(last_date.tz_localize(dt.UTC),today)
            if last_date.tz_localize(dt.UTC) < today:
                df_new = coinbase_price_history(pair=token,
                                            start_date=last_date.strftime('%Y-%m-%dT%H:%M:%SZ'),
                                            end_date=today.strftime('%Y-%m-%dT%H:%M:%SZ'),
                                            time_interval=interval)
                df = pd.concat([df,df_new])
                # drop duplicates and sort by date
                df = df.drop_duplicates(subset='datetime').sort_values(by='datetime').reset_index(drop=True)
                save_file(df,folder_path,token,type)
            else:
                print(f"File {token} is up to date")
        else:
            df = coinbase_price_history(pair=token,
                                        start_date='2016-01-01T00:00:00Z',
                                        end_date=datetime.now().strftime('%Y-%m-%dT%H:%M:%SZ'),
                                        time_interval=interval)
            save_file(df,folder_path,token,type)
    


# %% ../nbs/coinbase.ipynb 10
def read_all_files(folder_path="../data/coinbase",type="csv"):
    file_names = os.listdir(folder_path)
    df_list = []
    for file_name in file_names:
        if type == "csv":
            df = pd.read_csv(f"{folder_path}/{file_name}")
        elif type == "parquet":
            df = pd.read_parquet(f"{folder_path}/{file_name}")
        else:
            raise ValueError(f"Type {type} not supported")
        df_list.append(df)
    return pd.concat(df_list)


